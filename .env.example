# Submission API
API_HOSTNAME="0.0.0.0"
API_PORT="8000"

# Provisioner SSH Keys
PROVISIONER_SSH_PRIVATE_KEY_PATH="/path/to/provisioner_ssh_key"
PROVISIONER_SSH_PUBLIC_KEY_PATH="/path/to/provisioner_ssh_key.pub"

# Cloudlab Credentials
CLOUDLAB_CERT_PATH="/path/to/cloudlab.pem"
CLOUDLAB_KEY_PATH="/path/to/cloudlab_decrypted.pem"
CLOUD_PROJECT_NAME="your-cloudlab-project-name"

# GitHub Deploy key
DEPLOY_KEY_PATH="/path/to/deploy-key"

# Optional Credentials for Email Notificaitons
SMTP_SERVER="smtp.gmail.com"
SMTP_PORT="587"
SMTP_USERNAME="your.email@gmail.com"
SMTP_PASSWORD="your-app-password"

# MCP Server Setting
MCP_SERVER_PORT=8001
EXPOSE_SERVER=False
# The size of session that can be hold at most; LRU session will be evicted if overflowing
SESSION_CACHE_SIZE=10000
# The time after which the session will be considered inactive if no interaction with the server;
# Cache of inactive session will be deleted in the next cache mutating operation
SESSION_TTL=600

# LangGraph Tool Setting
MCP_SERVER_URL=http://127.0.0.1:${MCP_SERVER_PORT}

# Agent LLM Config
# Maximum number of retries for API calls
LLM_QUERY_MAX_RETRIES=5
# Initial delay in seconds for retries
LLM_QUERY_INIT_RETRY_DELAY=1


### LLM Config1: LiteLLM ###
# PROVIDER_TOOLS="litellm" 
# PROVIDER="litellm"

# MODEL_TOOLS="gemini/gemini-2.5-flash"
# MODEL_TOOLS="openai/gpt-4o"
# MODEL_TOOLS="anthropic/claude-sonnet-4-20250514" # this one is ok, but the model on the doc of LiteLLM seems to be invalid. 

# GEMINI_API_KEY="AIHaveFreeFood_LotsOfIt"
# OPENAI_API_KEY="sk-proj-HaveSleep_LotsOfIt"
# ANTHROPIC_API_KEY="sk-ant-api03-HaveCats_LotsOfIt_Meow"


### LLM Config2: WatsonX ###
# PROVIDER_TOOLS="watsonx"
# PROVIDER="watsonx"
# MODEL_TOOLS="meta-llama/llama-3-3-70b-instruct"
# URL_TOOLS="https://us-south.ml.cloud.ibm.com"
# API_KEY_TOOLS="HaveCornsLotsOfIt"
# WATSONX_API_BASE="https://us-south.ml.cloud.ibm.com"
# WX_PROJECT_ID="fe3d8da2-be7e-41b2-8d92-f0e855869e28"
# WATSONX_API_KEY="HaveCornsLotsOfIt"

### LLM Config3: LiteLLM not supported but OpenAI API compatible ###
# PROVIDER="compatible"
# PROVIDER_TOOLS="compatible"

# MODEL_TOOLS="openai/glm-4" # you should use 'openai' as the provider to reuse the interface
# API_KEY_TOOLS="HaveFunding_LotsOfIt"
# URL_TOOLS="https://open.bigmodel.cn/api/paas/v4/" # the base url of the model, taking Zhipu GLM as the example

